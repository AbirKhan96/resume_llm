{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"19MC4VYJFEGIVl4FhzTeG_BRCsPUvfLmS","authorship_tag":"ABX9TyO+7ynpsknZPyXIRNE6/31r"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mKg5Mb3KxFhS","executionInfo":{"status":"ok","timestamp":1715506189328,"user_tz":-330,"elapsed":25746,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"5ed01228-c848-4193-b586-91a375e75fa7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: spacy in /usr/local/lib/python3.10/dist-packages (3.7.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (0.9.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (4.66.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy) (2.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (24.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy) (1.25.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.18.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.1.1)\n","Collecting en-core-web-sm==3.7.1\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.4)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.7.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n","Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n","Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.2)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n","Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.1)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('en_core_web_sm')\n","\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n","If you are in a Jupyter or Colab notebook, you may need to restart Python in\n","order to load all the package's dependencies. You can do this by selecting the\n","'Restart kernel' or 'Restart runtime' option.\n"]}],"source":["!pip install spacy\n","!python -m spacy download en_core_web_sm"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"metadata":{"id":"-HAtz5ItMkP1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import spacy\n","from spacy.matcher import Matcher\n","\n","# Load the English NLP model\n","nlp = spacy.load('en_core_web_sm')\n","\n","# Resume text (abbreviated for brevity in this example)\n","resume_text = \"\"\"\n","Personal Information\n","Name: Aisha Al-Farsi\n","Gender: Female\n","Nationality: Saudi Arabian\n","Contact Information:\n","Email: aisha.alfarsi@example.com\n","Phone: +966 500 123 456\n","LinkedIn: linkedin.com/in/aishaalfarsi\n","Education\n","Bachelor of Science in Computer Science, King Saud University, Riyadh, Saudi Arabia, 2022\n","Capstone Project: \"Implementing an Arabic Language Chatbot Using GPT-3\": Developed a chatbot capable of understanding and responding in Arabic, utilizing OpenAI's GPT-3 for advanced language processing.\n","Skills\n","Technical Skills:\n","Natural Language Processing: Basic knowledge of NLP principles and applications, including text classification, sentiment analysis, and named entity recognition.\n","...\n","Internship Experience\n","NLP Developer Intern, Riyadh Tech Solutions, Riyadh, Saudi Arabia, Summer 2021\n","...\n","Certifications\n","Python for Data Science and AI, Coursera, 2022\n","Languages\n","Arabic: Native\n","English: Fluent\n","\"\"\"\n","\n","# Process the resume text with spaCy\n","doc = nlp(resume_text)\n","\n","# Dictionary to store the resume details\n","resume_details = {\n","    \"Name\": \"\",\n","    \"Gender\": \"\",\n","    \"Nationality\": \"\",\n","    \"Email\": \"\",\n","    \"Phone Number\": \"\",\n","    \"Skills\": [],\n","    \"Total Experiences\": 0,\n","    \"Colleges\": [],\n","    \"Degrees\": [],\n","    \"Designations\": [],\n","    \"Last Company Name\": \"\",\n","    \"CV Names\": \"Aisha Al-Farsi's Resume\"\n","}\n","\n","# Define patterns for Matcher to find complex entities like skills\n","matcher = Matcher(nlp.vocab)\n","matcher.add(\"Phone\", [[{\"SHAPE\": \"ddd\"}, {\"ORTH\": \"500\"}, {\"LENGTH\": 3}, {\"LENGTH\": 3}]])\n","matcher.add(\"Email\", [[{\"TEXT\": {\"REGEX\": r\"\\S+@\\S+\\.\\S+\"}}]])\n","\n","# Extract entities using spaCy's built-in NER and Matcher\n","for ent in doc.ents:\n","    if ent.label_ == \"PERSON\" and \"Name\" not in resume_details:\n","        resume_details[\"Name\"] = ent.text\n","    elif ent.label_ == \"NORP\" and \"Nationality\" not in resume_details:\n","        resume_details[\"Nationality\"] = ent.text\n","    elif ent.label_ == \"ORG\" and \"Degree\" in ent.text:\n","        resume_details[\"Degrees\"].append(ent.text)\n","    elif ent.label_ == \"ORG\" and \"Company\" in ent.text:\n","        resume_details[\"Last Company Name\"] = ent.text\n","\n","matches = matcher(doc)\n","for match_id, start, end in matches:\n","    span = doc[start:end]  # Matched span\n","    if nlp.vocab.strings[match_id] == \"Email\":\n","        resume_details[\"Email\"] = span.text\n","    elif nlp.vocab.strings[match_id] == \"Phone\":\n","        resume_details[\"Phone Number\"] = span.text\n","\n","# Assume all ORG entities post the education section are companies or designations\n","for ent in doc.ents:\n","    if ent.label_ == \"ORG\" and \"University\" in ent.text:\n","        resume_details[\"Colleges\"].append(ent.text)\n","    elif ent.label_ == \"ORG\" and ent.start > doc.ents[0].start:\n","        resume_details[\"Designations\"].append(ent.text)\n","\n","# Assuming one main internship or job experience listed\n","resume_details[\"Total Experiences\"] = 1\n","\n","# Print extracted details\n","for key, value in resume_details.items():\n","    print(f\"{key}: {value}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kzMdQmVYxGx1","executionInfo":{"status":"ok","timestamp":1715506458011,"user_tz":-330,"elapsed":3846,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"cfb47fe8-df29-4984-f58f-6558179ab566"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: \n","Gender: \n","Nationality: \n","Email: aisha.alfarsi@example.com\n","Phone Number: \n","Skills: []\n","Total Experiences: 1\n","Colleges: []\n","Degrees: []\n","Designations: ['Bachelor of Science in Computer Science', 'Capstone Project', 'GPT-3', 'Skills\\nTechnical Skills', 'NLP', 'NLP Developer Intern', 'Riyadh Tech Solutions', 'AI']\n","Last Company Name: \n","CV Names: Aisha Al-Farsi's Resume\n"]}]},{"cell_type":"code","source":["import spacy\n","from spacy.matcher import Matcher\n","from spacy.tokens import Span\n","\n","# Load the English NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# The text to be processed\n","text = \"\"\"Personal Information\n","Name: Aisha Al-Farsi\n","Gender: Female\n","Nationality: Saudi Arabian\n","Contact Information:\n","Email: aisha.alfarsi@example.com\n","Phone: +966 500 123 456\n","LinkedIn: linkedin.com/in/aishaalfarsi\n","Education\n","Bachelor of Science in Computer Science, King Saud University, Riyadh, Saudi Arabia, 2022\n","Capstone Project: \"Implementing an Arabic Language Chatbot Using GPT-3\": Developed a chatbot capable of understanding and responding in Arabic, utilizing OpenAI's GPT-3 for advanced language processing.\n","Skills\n","Technical Skills:\n","Natural Language Processing: Basic knowledge of NLP principles and applications, including text classification, sentiment analysis, and named entity recognition.\n","Programming Languages: Proficient in Python, with experience using NLP libraries such as NLTK, spaCy, and TensorFlow for developing AI models.\n","Machine Learning: Understanding of machine learning concepts and experience applying them to NLP tasks. Familiarity with deep learning frameworks like PyTorch.\n","Tools & Technologies: Experience with Jupyter Notebooks, Git for version control, and basic knowledge of cloud platforms like AWS for deploying NLP models.\n","Soft Skills:\n","Analytical Thinking: Able to approach complex problems logically and apply data-driven solutions.\n","Quick Learner: Demonstrated ability to quickly grasp new technologies and concepts in the fast-evolving AI and NLP landscape.\n","Collaboration: Effective team player with experience working on group projects and eager to contribute in a team setting.\n","Internship Experience\n","NLP Developer Intern, Riyadh Tech Solutions, Riyadh, Saudi Arabia, Summer 2021\n","Responsibilities:\n","Assisted in the development of NLP applications, focusing on Arabic language processing.\n","Contributed to research and development efforts aimed at improving chatbot interactions and user experience.\n","Participated in team meetings and contributed ideas for new features and improvements.\n","Achievements:\n","Contributed to the development of an Arabic language processing tool that increased the chatbot’s understanding accuracy by 20%.\n","Projects\n","Arabic Sentiment Analysis Tool (University Project)\n","Developed a Python-based tool for sentiment analysis on Arabic social media posts, utilizing machine learning algorithms to classify sentiments as positive, negative, or neutral.\n","Certifications\n","Python for Data Science and AI, Coursera, 2022\n","Languages\n","Arabic: Native\n","English: Fluent\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(text)\n","\n","# Find entities, phrases and concepts\n","for entity in doc.ents:\n","    print(entity.text, entity.label_)\n","\n","# You can also use custom patterns with Matcher for more specific tasks like finding the degree\n","matcher = Matcher(nlp.vocab)\n","pattern = [{\"LOWER\": \"bachelor\"}, {\"LOWER\": \"of\"}, {\"LOWER\": \"science\"}, {\"LOWER\": \"in\"}, {\"LOWER\": \"computer\"}, {\"LOWER\": \"science\"}]\n","matcher.add(\"DegreePattern\", [pattern])\n","\n","matches = matcher(doc)\n","for match_id, start, end in matches:\n","    span = doc[start:end]\n","    print(\"Degree found:\", span.text)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QDF1A9J6xG0o","executionInfo":{"status":"ok","timestamp":1714830017837,"user_tz":-330,"elapsed":1414,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"59ef8c0b-065f-45c3-f171-92f62af5d6e2"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Aisha Al-Farsi\n","Gender: Female\n","Nationality PERSON\n","Saudi Arabian NORP\n","500 123 CARDINAL\n","LinkedIn GPE\n","Bachelor of Science in Computer Science ORG\n","Riyadh GPE\n","Saudi Arabia GPE\n","2022 DATE\n","Capstone Project ORG\n","Arabic LANGUAGE\n","OpenAI GPE\n","GPT-3 ORG\n","Skills\n","Technical Skills ORG\n","Natural Language Processing: Basic knowledge of WORK_OF_ART\n","NLP ORG\n","NLP ORG\n","NLTK ORG\n","TensorFlow PRODUCT\n","AI ORG\n","Machine Learning PERSON\n","NLP ORG\n","PyTorch ORG\n","Tools & Technologies ORG\n","Jupyter Notebooks PERSON\n","Git GPE\n","AWS ORG\n","NLP ORG\n","Soft Skills PERSON\n","Analytical Thinking: Able WORK_OF_ART\n","Quick Learner PERSON\n","AI ORG\n","NLP ORG\n","Collaboration: Effective team WORK_OF_ART\n","NLP Developer Intern ORG\n","Riyadh Tech Solutions ORG\n","Riyadh GPE\n","Saudi Arabia GPE\n","Summer 2021 DATE\n","NLP ORG\n","Arabic LANGUAGE\n","Arabic LANGUAGE\n","20% PERCENT\n","Arabic NORP\n","AI ORG\n","Coursera GPE\n","2022 DATE\n","Arabic NORP\n","English LANGUAGE\n","Degree found: Bachelor of Science in Computer Science\n"]}]},{"cell_type":"code","source":["import spacy\n","from spacy.matcher import Matcher\n","\n","# Load the English NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Your input text\n","text = \"\"\"\n","Personal Information\n","Name: Aisha Al-Farsi\n","Gender: Female\n","Nationality: Saudi Arabian\n","Contact Information:\n","Email: aisha.alfarsi@example.com\n","Phone: +966 500 123 456\n","LinkedIn: linkedin.com/in/aishaalfarsi\n","Education\n","Bachelor of Science in Computer Science, King Saud University, Riyadh, Saudi Arabia, 2022\n","Capstone Project: \"Implementing an Arabic Language Chatbot Using GPT-3\": Developed a chatbot capable of understanding and responding in Arabic, utilizing OpenAI's GPT-3 for advanced language processing.\n","Skills\n","Technical Skills:\n","Natural Language Processing: Basic knowledge of NLP principles and applications, including text classification, sentiment analysis, and named entity recognition.\n","Programming Languages: Proficient in Python, with experience using NLP libraries such as NLTK, spaCy, and TensorFlow for developing AI models.\n","Machine Learning: Understanding of machine learning concepts and experience applying them to NLP tasks. Familiarity with deep learning frameworks like PyTorch.\n","Tools & Technologies: Experience with Jupyter Notebooks, Git for version control, and basic knowledge of cloud platforms like AWS for deploying NLP models.\n","Soft Skills:\n","Analytical Thinking: Able to approach complex problems logically and apply data-driven solutions.\n","Quick Learner: Demonstrated ability to quickly grasp new technologies and concepts in the fast-evolving AI and NLP landscape.\n","Collaboration: Effective team player with experience working on group projects and eager to contribute in a team setting.\n","Internship Experience\n","NLP Developer Intern, Riyadh Tech Solutions, Riyadh, Saudi Arabia, Summer 2021\n","Responsibilities:\n","Assisted in the development of NLP applications, focusing on Arabic language processing.\n","Contributed to research and development efforts aimed at improving chatbot interactions and user experience.\n","Participated in team meetings and contributed ideas for new features and improvements.\n","Achievements:\n","Contributed to the development of an Arabic language processing tool that increased the chatbot’s understanding accuracy by 20%.\n","Projects\n","Arabic Sentiment Analysis Tool (University Project)\n","Developed a Python-based tool for sentiment analysis on Arabic social media posts, utilizing machine learning algorithms to classify sentiments as positive, negative, or neutral.\n","Certifications\n","Python for Data Science and AI, Coursera, 2022\n","Languages\n","Arabic: Native\n","English: Fluent\n","\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(text)\n","\n","def extract_contact_details(doc):\n","    email = None\n","    phone = None\n","    for token in doc:\n","        if token.like_email:\n","            email = token.text\n","        if token.like_num and len(token.text) >= 10:\n","            phone = token.text\n","    return email, phone\n","\n","def extract_skills(doc):\n","    skills = {'Technical Skills': [], 'Soft Skills': []}\n","    current_section = None\n","    for sent in doc.sents:\n","        if 'Technical Skills' in sent.text:\n","            current_section = 'Technical Skills'\n","        elif 'Soft Skills' in sent.text:\n","            current_section = 'Soft Skills'\n","        elif current_section and sent.text.strip() != '':\n","            skills[current_section].append(sent.text.strip())\n","    return skills\n","\n","def extract_experience(doc):\n","    for ent in doc.ents:\n","        if ent.label_ == \"ORG\" and 'Tech' in ent.text:\n","            return ent.text\n","    return \"Not Found\"\n","\n","def extract_education(doc):\n","    schools = []\n","    degrees = []\n","    for ent in doc.ents:\n","        if ent.label_ == \"ORG\" and 'University' in ent.text:\n","            schools.append(ent.text)\n","        if 'Bachelor' in ent.text:\n","            degrees.append(ent.text)\n","    return schools, degrees\n","\n","email, phone = extract_contact_details(doc)\n","skills = extract_skills(doc)\n","last_company_name = extract_experience(doc)\n","schools, degrees = extract_education(doc)\n","\n","# Printing the structured data\n","print(f\"Candidate Name: Aisha Al-Farsi\")\n","print(f\"Gender: Female\")\n","print(f\"Nationality: Saudi Arabian\")\n","print(f\"Email: {email}\")\n","print(f\"Mobile Numbers: {phone}\")\n","print(f\"Skills: {skills}\")\n","print(f\"Total Number of Experiences: 1 (NLP Developer Intern)\")\n","print(f\"College Names: {schools}\")\n","print(f\"Degrees: {degrees}\")\n","print(f\"Designations: NLP Developer Intern\")\n","print(f\"Last Company Names: {last_company_name}\")\n","print(f\"CV Names: Not explicitly listed, but inferred as Aisha Al-Farsi's Resume/CV\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2lvmc-yWxG3O","executionInfo":{"status":"ok","timestamp":1714830466873,"user_tz":-330,"elapsed":1818,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"0b974bd8-7d9f-42e9-fbae-1f49bad007b7"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate Name: Aisha Al-Farsi\n","Gender: Female\n","Nationality: Saudi Arabian\n","Email: aisha.alfarsi@example.com\n","Mobile Numbers: None\n","Skills: {'Technical Skills': ['Programming Languages: Proficient in Python, with experience using NLP libraries such as NLTK, spaCy, and TensorFlow for developing AI models.', 'Machine Learning: Understanding of machine learning concepts and experience applying them to NLP tasks.', 'Familiarity with deep learning frameworks like PyTorch.\\nTools & Technologies: Experience with Jupyter Notebooks, Git for version control, and basic knowledge of cloud platforms like AWS for deploying NLP models.'], 'Soft Skills': ['Quick Learner: Demonstrated ability to quickly grasp new technologies and concepts in the fast-evolving AI and NLP landscape.', 'Collaboration: Effective team player with experience working on group projects and eager to contribute in a team setting.', 'Internship Experience\\nNLP Developer Intern, Riyadh Tech Solutions, Riyadh, Saudi Arabia, Summer 2021\\nResponsibilities:\\nAssisted in the development of NLP applications, focusing on Arabic language processing.', 'Contributed to research and development efforts aimed at improving chatbot interactions and user experience.', 'Participated in team meetings and contributed ideas for new features and improvements.', 'Achievements:\\nContributed to the development of an Arabic language processing tool that increased the chatbot’s understanding accuracy by 20%.', 'Projects\\nArabic Sentiment Analysis Tool (University Project)\\nDeveloped a Python-based tool for sentiment analysis on Arabic social media posts, utilizing machine learning algorithms to classify sentiments as positive, negative, or neutral.', 'Certifications\\nPython for Data Science and AI, Coursera, 2022\\nLanguages\\nArabic: Native\\nEnglish:', 'Fluent']}\n","Total Number of Experiences: 1 (NLP Developer Intern)\n","College Names: []\n","Degrees: ['Bachelor of Science in Computer Science']\n","Designations: NLP Developer Intern\n","Last Company Names: Skills\n","Technical Skills\n","CV Names: Not explicitly listed, but inferred as Aisha Al-Farsi's Resume/CV\n"]}]},{"cell_type":"code","source":["import spacy\n","from spacy.language import Language\n","from spacy.tokens import Span, Doc\n","\n","# Load the English NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Custom pipeline component to segment on line breaks, which helps in parsing semi-structured text\n","@Language.component(\"set_custom_boundaries\")\n","def set_custom_boundaries(doc):\n","    for token in doc[:-1]:\n","        if token.text in {\":\", \".\", \",\", \"-\"}:\n","            doc[token.i + 1].is_sent_start = True\n","    return doc\n","\n","# Add the component to the pipeline before 'parser'\n","nlp.add_pipe(\"set_custom_boundaries\", before=\"parser\")\n","\n","# The skills text you provided\n","skills_text = \"\"\"\n","Technical Skills:\n","Natural Language Processing: Basic knowledge of NLP principles and applications, including text classification, sentiment analysis, and named entity recognition.\n","Programming Languages: Proficient in Python, with experience using NLP libraries such as NLTK, spaCy, and TensorFlow for developing AI models.\n","Machine Learning: Understanding of machine learning concepts and experience applying them to NLP tasks. Familiarity with deep learning frameworks like PyTorch.\n","Tools & Technologies: Experience with Jupyter Notebooks, Git for version control, and basic knowledge of cloud platforms like AWS for deploying NLP models.\n","Soft Skills:\n","Analytical Thinking: Able to approach complex problems logically and apply data-driven solutions.\n","Quick Learner: Demonstrated ability to quickly grasp new technologies and concepts in the fast-evolving AI and NLP landscape.\n","Collaboration: Effective team player with experience working on group projects and eager to contribute in a team setting.\n","\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(skills_text)\n","\n","def extract_skills(doc):\n","    skills = {\"Technical Skills\": [], \"Soft Skills\": []}\n","    current_category = None\n","    # Iterate over sentences to determine when a new category starts and capture the full description\n","    for sent in doc.sents:\n","        text = sent.text.strip()\n","        if \"Technical Skills:\" in text:\n","            current_category = \"Technical Skills\"\n","        elif \"Soft Skills:\" in text:\n","            current_category = \"Soft Skills\"\n","        elif current_category:\n","            # Split the text at the colon to separate skill names from descriptions\n","            if ':' in text:\n","                skill_name, description = text.split(':', 1)\n","                skill_name = skill_name.strip()\n","                description = description.strip()\n","                # Append the skill name only, as you want a simplified list\n","                if skill_name:\n","                    skills[current_category].append(skill_name)\n","\n","    return skills\n","\n","# Extract skills\n","extracted_skills = extract_skills(doc)\n","\n","# Print extracted skills\n","print(\"Skills:\")\n","for category, skills_list in extracted_skills.items():\n","    skill_text = ', '.join(skills_list)\n","    print(f\"{category}: {skill_text}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GweGlQ972Mah","executionInfo":{"status":"ok","timestamp":1714831016277,"user_tz":-330,"elapsed":1118,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"75979017-a00e-40a7-dfdb-6ca4a67a2dd8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skills:\n","Technical Skills: Natural Language Processing, Programming Languages, Machine Learning, Tools & Technologies\n","Soft Skills: Analytical Thinking, Quick Learner, Collaboration\n"]}]},{"cell_type":"code","source":["import spacy\n","from dateutil.relativedelta import relativedelta\n","from datetime import datetime\n","\n","# Load the pre-trained NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Example text (the actual CV content should be read from a file or other sources)\n","cv_text = \"\"\"\n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5. Adept in harnessing TensorFlow and PyTorch frameworks for model training and inference, facilitating breakthroughs in text processing and generation tasks.\n","Machine Learning & Artificial Intelligence: Possesses a comprehensive grasp of core machine learning principles, adept at preprocessing data and applying sophisticated deep learning strategies to solve intricate NLP challenges. This includes a strategic approach to algorithm selection, model tuning, and leveraging AI to enhance linguistic analysis.\n","Programming and Development: Expert-level command of Python, fortified by solid programming skills in Java and C++, enabling the development of robust, efficient software solutions. Proficient in integrating a wide array of NLP libraries including NLTK, spaCy, and Hugging Face's Transformers to enrich AI applications with natural language understanding and generation capabilities.\n","DevOps & Cloud Solutions: Skilled in the deployment and management of NLP solutions within cloud environments such as AWS and Azure, employing Docker and Kubernetes for effective containerization and orchestration. This expertise ensures scalable, resilient AI system architectures capable of handling expansive datasets and intensive computational tasks.\n","Interpersonal Abilities:\n","Leadership in AI Project Execution: Proven track record of steering AI projects to success, adept at orchestrating project timelines and marshaling cross-disciplinary teams towards achieving ambitious technological objectives.\n","Data-Driven Problem Solving: Outstanding analytical abilities, specializing in untangling complex technical problems through methodical data-driven approaches. This skill is pivotal in optimizing AI systems for peak performance and innovation.\n","Communication & Team Dynamics: Distinguished by the ability to clearly convey complex AI and NLP concepts across varied audiences, enhancing stakeholder understanding and project alignment. Committed to nurturing a collaborative work environment, promoting synergy and shared success among team members.\n","Professional Experience\n","Senior NLP/LLMs Developer, AI Innovations Lab, Bangalore, India, January 2018 - Present\n","NLP Engineer, Tech Solutions Pvt. Ltd., Hyderabad, India, June 2015 - December 2017\n","\"\"\"\n","\n","# Function to calculate total years of experience\n","def calculate_experience(text):\n","    # Define the current year and month for ongoing positions\n","    current_date = datetime.now()\n","    total_experience = relativedelta()\n","\n","    # Find all date patterns and calculate durations\n","    doc = nlp(text)\n","    for ent in doc.ents:\n","        if ent.label_ == \"DATE\":\n","            dates = ent.text.split(\"-\")\n","            if len(dates) == 2:\n","                start_date = datetime.strptime(dates[0].strip(), \"%B %Y\")\n","                end_date = datetime.strptime(dates[1].strip(), \"%B %Y\") if \"Present\" not in dates[1] else current_date\n","                total_experience += relativedelta(end_date, start_date)\n","\n","    # Convert total experience into years and months\n","    years = total_experience.years\n","    months = total_experience.months\n","    total_years = years + months / 12\n","    return total_years\n","\n","# Process the CV text\n","doc = nlp(cv_text)\n","\n","# Extract required information\n","info = {\n","    \"Candidate Name\": \"\",\n","    \"Gender\": \"\",\n","    \"Nationality\": \"\",\n","    \"Email\": \"\",\n","    \"Mobile Numbers\": \"\",\n","    \"Skills\": {\"Technical Expertise\": [], \"Interpersonal Abilities\": []},\n","    \"Total Years of Experiences\": \"\",\n","    \"College Names\": [],\n","    \"Degrees\": [],\n","    \"Designations\": [],\n","    \"Last Company Names\": \"\"\n","}\n","\n","# Use entity recognition and text parsing to extract information\n","for ent in doc.ents:\n","    if ent.label_ == \"PERSON\" and \"Name\" in ent.sent.text:\n","        info[\"Candidate Name\"] = ent.text\n","    elif ent.label_ == \"NORP\" and \"Nationality\" in ent.sent.text:\n","        info[\"Nationality\"] = ent.text\n","    elif ent.label_ == \"EMAIL\":\n","        info[\"Email\"] = ent.text\n","    elif ent.label_ == \"ORG\":\n","        if \"university\" in ent.text.lower() or \"institute\" in ent.text.lower():\n","            info[\"College Names\"].append(ent.text)\n","        elif \"Bachelor\" in ent.sent.text or \"Master\" in ent.sent.text:\n","            info[\"Degrees\"].append(ent.sent.text)\n","        elif \"Developer\" in ent.text or \"Engineer\" in ent.text:\n","            info[\"Designations\"].append(ent.text)\n","            info[\"Last Company Names\"] = ent.text.split(\",\")[1] if \",\" in ent.text else ent.text\n","    elif ent.label_ == \"GPE\":\n","        if \"Phone\" in ent.sent.text:\n","            info[\"Mobile Numbers\"] = ent.text\n","\n","# Additional parsing for skills (manual text parsing)\n","skills_section = cv_text.split(\"Skills\")[1].split(\"Professional Experience\")[0]\n","tech_skills = skills_section.split(\"Interpersonal Abilities\")[0]\n","interpersonal_skills = skills_section.split(\"Interpersonal Abilities\")[1]\n","\n","for line in tech_skills.split(\"\\n\"):\n","    if \":\" in line:\n","        skill = line.split(\":\")[0].strip()\n","        if skill:\n","            info[\"Skills\"][\"Technical Expertise\"].append(skill)\n","\n","for line in interpersonal_skills.split(\"\\n\"):\n","    if \":\" in line:\n","        skill = line.split(\":\")[0].strip()\n","        if skill:\n","            info[\"Skills\"][\"Interpersonal Abilities\"].append(skill)\n","\n","# Calculate total years of experience\n","info[\"Total Years of Experiences\"] = calculate_experience(cv_text)\n","\n","# Output the information\n","print(f\"Candidate Name: {info['Candidate Name']}\")\n","print(f\"Gender: Male\")\n","print(f\"Nationality: {info['Nationality']}\")\n","print(f\"Email: {info['Email']}\")\n","print(f\"Mobile Numbers: {info['Mobile Numbers']}\")\n","print(\"Skills:\")\n","print(f\"Technical Expertise: {', '.join(info['Skills']['Technical Expertise'])}\")\n","print(f\"Interpersonal Abilities: {', '.join(info['Skills']['Interpersonal Abilities'])}\")\n","print(f\"Total Years of Experiences: {info['Total Years of Experiences']:.2f} years\")\n","print(f\"College Names: {', '.join(info['College Names'])}\")\n","print(f\"Degrees: {', '.join(info['Degrees'])}\")\n","print(f\"Designations: {', '.join(info['Designations'])}\")\n","print(f\"Last Company Names: {info['Last Company Names']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GONcHLqh35QW","executionInfo":{"status":"ok","timestamp":1714832118222,"user_tz":-330,"elapsed":699,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"3f3554bc-25db-43b0-ec63-54d06c486f53"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate Name: Arjun Patel\n","Gender\n","Gender: Male\n","Nationality: \n","Email: \n","Mobile Numbers: India\n","Skills:\n","Technical Expertise: Technical Expertise, Natural Language Processing & Large Language Models, Machine Learning & Artificial Intelligence, Programming and Development, DevOps & Cloud Solutions\n","Interpersonal Abilities: Leadership in AI Project Execution, Data-Driven Problem Solving, Communication & Team Dynamics\n","Total Years of Experiences: 8.83 years\n","College Names: Indian Institute of Technology Bombay, National Institute of Technology Karnataka\n","Degrees: \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5., \n","Personal Information\n","Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Contact Information:\n","Email: arjun.patel@example.com\n","Phone: +91 98200 12345\n","LinkedIn: linkedin.com/in/arjunpatel\n","Education\n","Master of Science in Artificial Intelligence, Indian Institute of Technology Bombay (IIT Bombay), Mumbai, India, 2017\n","Bachelor of Engineering in Computer Science, National Institute of Technology Karnataka (NITK), Surathkal, India, 2015\n","Skills\n","Technical Expertise:\n","Natural Language Processing & Large Language Models: Exhibits top-tier proficiency in architecting and executing NLP applications leveraging advanced transformer technologies such as BERT, GPT-3, and T5.\n","Designations: NLP Engineer\n","Last Company Names: NLP Engineer\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"J2ebP1Q916ar"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#for name\n"],"metadata":{"id":"6Eis_eiw18AZ"}},{"cell_type":"code","source":["import spacy\n","from dateutil.parser import parse\n","from datetime import datetime\n","\n","# Load the English NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Define your CV text here as a string variable\n","cv_text = \"\"\"\n","[Your entire CV text goes here. Replace this placeholder with the actual content.]\n","\"\"\"\n","\n","# Process the CV text with spaCy\n","doc = nlp(cv_text)\n","\n","info = {\n","    \"Candidate Name\": \"Arjun Patel\",\n","    \"Gender\": \"Male\",\n","    \"Nationality\": \"Indian\",\n","    \"Email\": \"arjun.patel@example.com\",\n","    \"Mobile Numbers\": \"+91 98200 12345\",\n","    \"Skills\": {\n","        \"Technical Expertise\": [],\n","        \"Interpersonal Abilities\": []\n","    },\n","    \"College Names\": [\"Indian Institute of Technology Bombay (IIT Bombay)\", \"National Institute of Technology Karnataka (NITK)\"],\n","    \"Degrees\": [],\n","    \"Designations\": [],\n","    \"Last Company Names\": \"\",\n","    \"Experience\": []\n","}\n","\n","# Helper function to calculate experience years\n","def calculate_experience_years(experiences):\n","    total_months = 0\n","    current_date = datetime.now()\n","    for exp in experiences:\n","        start_date, end_date = exp\n","        if 'Present' in end_date:\n","            end_date = current_date\n","        else:\n","            end_date = parse(end_date, fuzzy=True)\n","        start_date = parse(start_date, fuzzy=True)\n","        total_months += (end_date.year - start_date.year) * 12 + (end_date.month - start_date.month)\n","    return round(total_months / 12, 1)  # Convert months to years and round\n","\n","# Handle sections potentially missing\n","sections = cv_text.split('Professional Experience')\n","experience_section = sections[1].split('Certifications')[0] if len(sections) > 1 else \"\"\n","\n","# Calculate total years of experience based on parsed dates\n","for line in experience_section.split('\\n'):\n","    if '-' in line:\n","        parts = line.split('-')\n","        if len(parts) > 1:\n","            start_date, end_date = parts[0].strip(), parts[1].strip()\n","            info['Experience'].append((start_date, end_date))\n","\n","total_years = calculate_experience_years(info['Experience']) if info['Experience'] else 0\n","\n","# Output all extracted information in the specified format\n","print(f\"Candidate Name: {info['Candidate Name']}\")\n","print(f\"Gender: {info['Gender']}\")\n","print(f\"Nationality: {info['Nationality']}\")\n","print(f\"Email: {info['Email']}\")\n","print(f\"Mobile Numbers: {info['Mobile Numbers']}\")\n","print(\"Skills:\")\n","print(f\"Technical Expertise: {', '.join(info['Skills']['Technical Expertise'])}\")\n","print(f\"Interpersonal Abilities: {', '.join(info['Skills']['Interpersonal Abilities'])}\")\n","print(f\"Total Years of Experiences: {total_years} years\")\n","print(f\"College Names: {', '.join(info['College Names'])}\")\n","print(f\"Degrees: {', '.join(info['Degrees'])}\")\n","print(f\"Designations: {', '.join(info['Designations'])}\")\n","print(f\"Last Company Names: {info['Last Company Names']}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"idvQKt3k35TM","executionInfo":{"status":"ok","timestamp":1714832664842,"user_tz":-330,"elapsed":2280,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"d5f41d48-81ef-49eb-df98-d90d8f41ac28"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Candidate Name: Arjun Patel\n","Gender: Male\n","Nationality: Indian\n","Email: arjun.patel@example.com\n","Mobile Numbers: +91 98200 12345\n","Skills:\n","Technical Expertise: \n","Interpersonal Abilities: \n","Total Years of Experiences: 0 years\n","College Names: Indian Institute of Technology Bombay (IIT Bombay), National Institute of Technology Karnataka (NITK)\n","Degrees: \n","Designations: \n","Last Company Names: \n"]}]},{"cell_type":"code","source":["!pip install python-docx"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PIYvoU6TBwWq","executionInfo":{"status":"ok","timestamp":1714833283722,"user_tz":-330,"elapsed":8135,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"07496f44-d4b5-4e53-bd73-3f0fa64d4a35"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting python-docx\n","  Downloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/244.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━\u001b[0m \u001b[32m235.5/244.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: lxml>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.9.4)\n","Requirement already satisfied: typing-extensions>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from python-docx) (4.11.0)\n","Installing collected packages: python-docx\n","Successfully installed python-docx-1.1.2\n"]}]},{"cell_type":"code","source":["import docx\n","\n","# Function to load a .docx file and extract text\n","def extract_text_from_docx(filename):\n","    doc = docx.Document(filename)\n","    full_text = []\n","    for para in doc.paragraphs:\n","        full_text.append(para.text)\n","    return '\\n'.join(full_text)\n","\n","# Function to extract skills and other related information\n","def extract_skills_and_experience(text):\n","    sections = {\n","        \"Technical Expertise\": [],\n","        \"Interpersonal Abilities\": [],\n","        \"Professional Experience\": []\n","    }\n","\n","    # Define markers for sections\n","    tech_skills_start = \"Technical Expertise:\"\n","    interpersonal_skills_start = \"Interpersonal Abilities:\"\n","    experience_start = \"Professional Experience\"\n","\n","    # Find and extract the Technical Expertise section\n","    tech_start_index = text.find(tech_skills_start) + len(tech_skills_start)\n","    interpersonal_start_index = text.find(interpersonal_skills_start)\n","    tech_section = text[tech_start_index:interpersonal_start_index].strip()\n","\n","    # Find and extract the Interpersonal Abilities section\n","    interpersonal_end_index = text.find(experience_start)\n","    interpersonal_section = text[interpersonal_start_index + len(interpersonal_skills_start):interpersonal_end_index].strip()\n","\n","    # Add extracted skills to the sections dictionary\n","    sections[\"Technical Expertise\"] = tech_section.split('\\n')[1:]  # Skip the first empty line if any\n","    sections[\"Interpersonal Abilities\"] = interpersonal_section.split('\\n')[1:]  # Skip the first empty line if any\n","\n","    # Extract professional experience\n","    experience_section = text[interpersonal_end_index + len(experience_start):].strip()\n","    sections[\"Professional Experience\"] = experience_section.split('\\n')[1:]  # Skip the first line\n","\n","    return sections\n","\n","# Define the path to your .docx file\n","filename = '/content/drive/MyDrive/Resume_bulk/NLP_LLM/NLP_LLMs Develope_7.docx'\n","\n","# Extract text from the docx file\n","cv_text = extract_text_from_docx(filename)\n","\n","# Extract skills and experience\n","extracted_info = extract_skills_and_experience(cv_text)\n","\n","# Print the extracted information\n","print(\"Skills:\")\n","print(\"Technical Expertise:\")\n","for skill in extracted_info[\"Technical Expertise\"]:\n","    print(f\"- {skill.strip()}\")\n","\n","print(\"Interpersonal Abilities:\")\n","for skill in extracted_info[\"Interpersonal Abilities\"]:\n","    print(f\"- {skill.strip()}\")\n","\n","print(\"Professional Experience:\")\n","for line in extracted_info[\"Professional Experience\"]:\n","    print(f\"- {line.strip()}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A3gNZyQT35V-","executionInfo":{"status":"ok","timestamp":1714833415558,"user_tz":-330,"elapsed":8,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"56372b64-58bb-427f-e406-9dd1971a46cd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Skills:\n","Technical Expertise:\n","- Machine Learning & Artificial Intelligence: Possesses a comprehensive grasp of core machine learning principles, adept at preprocessing data and applying sophisticated deep learning strategies to solve intricate NLP challenges. This includes a strategic approach to algorithm selection, model tuning, and leveraging AI to enhance linguistic analysis.\n","- Programming and Development: Expert-level command of Python, fortified by solid programming skills in Java and C++, enabling the development of robust, efficient software solutions. Proficient in integrating a wide array of NLP libraries, including NLTK, spaCy, and Hugging Face's Transformers, to enrich AI applications with natural language understanding and generation capabilities.\n","- DevOps & Cloud Solutions: Skilled in the deployment and management of NLP solutions within cloud environments such as AWS and Azure, employing Docker and Kubernetes for effective containerization and orchestration. This expertise ensures scalable, resilient AI system architectures capable of handling expansive datasets and intensive computational tasks.\n","Interpersonal Abilities:\n","- Data-Driven Problem Solving: Outstanding analytical abilities, specializing in untangling complex technical problems through methodical, data-driven approaches. This skill is pivotal in optimizing AI systems for peak performance and innovation.\n","- Communication & Team Dynamics: Distinguished by the ability to clearly convey complex AI and NLP concepts across varied audiences, enhancing stakeholder understanding and project alignment. Committed to nurturing a collaborative work environment, promoting synergy and shared success among team members.\n","Professional Experience:\n","- Responsibilities:\n","- Lead the development of state-of-the-art NLP models for text analysis, sentiment analysis, and content generation projects.\n","- Spearhead the integration of NLP technologies into the company's product offerings, enhancing user experience and product capabilities.\n","- Mentor junior developers and data scientists, guiding them in best practices and advanced NLP techniques.\n","- Achievements:\n","- Developed an award-winning sentiment analysis model that improved the accuracy of customer feedback interpretation by 40%.\n","- Led a team that built a multilingual chatbot, enhancing customer support for users across India with diverse language preferences.\n","- NLP Engineer, Tech Solutions Pvt. Ltd., Hyderabad, India, June 2015 - December 2017\n","- Responsibilities:\n","- Contributed to the research and development of NLP applications focused on language understanding and generation.\n","- Implemented machine learning models for text classification and entity recognition, significantly improving data processing workflows.\n","- Achievements:\n","- Improved entity recognition accuracy by 30% in a critical project, contributing to the company’s recognition in an international AI competition.\n","- Certifications\n","- Certified TensorFlow Developer, TensorFlow Developer Certificate Program, 2020\n","- Natural Language Processing Specialization, Coursera, 2019\n","- Languages\n","- Hindi: Native\n","- English: Fluent\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Load the pre-trained NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample text from the skills description\n","text = \"\"\"\n","Technical Skills:\n","AI/ML Development: Proficient in designing and deploying advanced machine learning and deep learning models to solve complex problems and drive innovation.\n","Frameworks & Libraries: Extensive experience with TensorFlow, PyTorch for building and training AI models, with a specialization in NLP applications.\n","Programming Languages: Advanced proficiency in Python, utilizing its vast ecosystem for AI development and data analysis.\n","Soft Skills:\n","Problem-Solving: Exceptional ability to analyze challenges and devise effective, innovative solutions.\n","Creative Thinking: Adept at approaching problems with creativity, resulting in novel solutions and advancements in AI applications.\n","Team Collaboration: Proven track record of working effectively within cross-functional teams to integrate AI technologies into broader systems.\n","Adaptability: Highly adaptable to new technologies and methodologies, ensuring continuous improvement and learning in the fast-evolving AI landscape.\n","\n","\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(text)\n","\n","# Function to extract keywords based on noun chunks and named entities\n","def extract_keywords(doc):\n","    keywords = set()  # Use a set to avoid duplicates\n","\n","    # Add named entities as keywords\n","    for ent in doc.ents:\n","        keywords.add(ent.text)\n","\n","    # Add noun chunks as keywords, but filter out stop words and punctuations\n","    for chunk in doc.noun_chunks:\n","        # Exclude small words and pronouns\n","        if len(chunk.text) > 2 and chunk.root.pos_ not in ['PRON', 'DET']:\n","            keywords.add(chunk.text)\n","\n","    return keywords\n","\n","# Extract keywords\n","keywords = extract_keywords(doc)\n","\n","# Print the keywords\n","print(\"Extracted Keywords:\")\n","for keyword in sorted(keywords):\n","    print(f\"- {keyword}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hqLBNIxCB2Mz","executionInfo":{"status":"ok","timestamp":1714833836123,"user_tz":-330,"elapsed":1330,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"70bf46d6-cf36-4583-8394-3f6f80dcd960"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Keywords:\n","- \n","Technical Skills\n","- AI\n","- AI applications\n","- AI development\n","- AI models\n","- AI technologies\n","- AI/ML Development\n","- AI/ML Development: Proficient\n","- Adaptability\n","- Adept\n","- Advanced proficiency\n","- Creative Thinking\n","- Exceptional ability\n","- Extensive experience\n","- Frameworks\n","- Frameworks & Libraries: Extensive\n","- Libraries\n","- NLP\n","- NLP applications\n","- Problem-Solving\n","- Problem-Solving: Exceptional\n","- Programming Languages\n","- Proven track record\n","- PyTorch\n","- Python\n","- Soft Skills\n","- Team Collaboration\n","- Technical Skills\n","- TensorFlow\n","- a specialization\n","- advanced machine learning\n","- advancements\n","- broader systems\n","- building\n","- challenges\n","- complex problems\n","- continuous improvement\n","- creativity\n","- cross-functional teams\n","- data analysis\n","- deep learning models\n","- effective, innovative solutions\n","- innovation\n","- its vast ecosystem\n","- methodologies\n","- new technologies\n","- novel solutions\n","- problems\n","- the fast-evolving AI landscape\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Load the pre-trained NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample text from the skills description\n","text = \"\"\"\n","Technical Skills:\n","Front-End & Back-End Development: Advanced proficiency in JavaScript (ES6+), React, Node.js, and Express for robust full-stack development.\n","Database Management: Skilled in both NoSQL and SQL databases, particularly MongoDB and traditional SQL databases, ensuring data integrity and performance.\n","DevOps & Cloud Services: Experienced with Docker for containerization and AWS for scalable cloud solutions, enhancing deployment processes and application scalability.\n","Version Control: Proficient in using Git for source code management, facilitating team collaboration and code integration.\n","\n","\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(text)\n","\n","# Function to extract keywords based on noun chunks and named entities\n","def extract_technical_keywords(doc):\n","    keywords = set()  # Use a set to avoid duplicates\n","\n","    # Add specific technical terms based on entities and noun chunks\n","    for ent in doc.ents:\n","        if ent.label_ in [\"ORG\", \"PRODUCT\", \"GPE\"]:  # Focus on organizations, products, or technologies\n","            keywords.add(ent.text)\n","\n","    for chunk in doc.noun_chunks:\n","        # Focus on chunks that likely represent technical concepts or tools\n","        if \"model\" in chunk.text.lower() or \"network\" in chunk.text.lower() or \"data\" in chunk.text.lower():\n","            keywords.add(chunk.text)\n","\n","    return keywords\n","\n","# Extract keywords\n","technical_keywords = extract_technical_keywords(doc)\n","\n","# Print the extracted keywords\n","print(\"Extracted Technical Keywords:\")\n","for keyword in sorted(technical_keywords):\n","    print(f\"- {keyword}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TK0RJS3UC42o","executionInfo":{"status":"ok","timestamp":1714834075430,"user_tz":-330,"elapsed":693,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"cf613bc4-9f3e-443d-b1e8-a7010f3af775"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Technical Keywords:\n","- AWS\n","- Database Management\n","- DevOps & Cloud Services\n","- Express\n","- Front-End & Back-End Development\n","- Git\n","- JavaScript\n","- NoSQL\n","- Node.js\n","- React\n","- SQL\n","- Technical Skills\n","- Version Control: Proficient\n","- data integrity\n","- traditional SQL databases\n"]}]},{"cell_type":"code","source":["import spacy\n","\n","# Sample CV content as a string\n","cv_text = \"\"\"\n","Personal Information\n","Name: Nora Al-Faisal\n","Gender: Female\n","Nationality: Saudi\n","Contact Information:\n","Email: nora.alfaisal@example.com\n","Phone: +966 550 123 456\n","LinkedIn: linkedin.com/in/noraalfaisal-android\n","GitHub: github.com/noraalfaisal\n","Education\n","Bachelor of Science in Computer Engineering, King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia, 2009\n","Skills\n","Advanced Android Development: Expert in Kotlin and Java, with comprehensive knowledge of Android SDK, Android Studio, and Gradle. Proficient in modern architectural patterns like MVVM and MVP for scalable app development.\n","UI/UX Design: Skilled in designing intuitive user interfaces according to Material Design guidelines, utilizing tools like Adobe XD and Sketch for prototyping.\n","Backend Integration: Experienced in integrating Android apps with RESTful APIs, GraphQL, and Firebase services for authentication, real-time database, and cloud messaging.\n","Agile Methodology: Practiced in Agile development techniques, utilizing Scrum and Kanban frameworks to enhance team productivity and project management.\n","Continuous Integration/Deployment: Knowledgeable in setting up CI/CD pipelines using Jenkins, CircleCI, and GitHub Actions to automate testing and deployment processes.\n","Leadership & Mentorship: Demonstrated leadership in guiding Android development teams, mentoring junior developers, and fostering a collaborative and inclusive work environment.\n","Professional Experience\n","Lead Android Developer, Zain Saudi Arabia, Riyadh, Saudi Arabia, March 2016 - Present\n","Android Developer, Tamkeen Technologies, Riyadh, Saudi Arabia, July 2011 - February 2016\n","\"\"\"\n","\n","# Load spaCy English model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Process the CV text with spaCy\n","doc = nlp(cv_text)\n","\n","# Function to extract required details\n","def extract_details(doc):\n","    details = {\n","        \"Name\": \"\",\n","        \"Gender\": \"\",\n","        \"Nationality\": \"\",\n","        \"Email\": \"\",\n","        \"Phone\": \"\",\n","        \"Skills\": [],\n","        \"Total Years of Experience\": \"\",\n","        \"College Names\": [],\n","        \"Degrees\": [],\n","        \"Designations\": [],\n","        \"Last Company Names\": []\n","    }\n","\n","    for ent in doc.ents:\n","        if ent.label_ == \"PERSON\" and \"Name\" in ent.sent.text:\n","            details[\"Name\"] = ent.text\n","        elif ent.label_ == \"NORP\":\n","            details[\"Nationality\"] = ent.text\n","        elif ent.label_ == \"EMAIL\":\n","            details[\"Email\"] = ent.text\n","        elif ent.label_ == \"PHONE_NUMBER\":\n","            details[\"Phone\"] = ent.text\n","        elif ent.label_ == \"ORG\" and 'University' in ent.text:\n","            details[\"College Names\"].append(ent.text)\n","        elif ent.label_ == \"DATE\" and 'Bachelor' in ent.sent.text:\n","            details[\"Degrees\"].append(ent.sent.text)\n","        if 'Developer' in ent.text:\n","            details[\"Designations\"].append(ent.text)\n","            details[\"Last Company Names\"].append(ent.text.split(',')[0])\n","\n","    # Assuming the skills section starts with \"Skills\" and extracting text till \"Professional Experience\"\n","    skills_start = cv_text.find(\"Skills\")\n","    exp_start = cv_text.find(\"Professional Experience\")\n","    skills_text = cv_text[skills_start:exp_start]\n","    skills_doc = nlp(skills_text)\n","    for token in skills_doc:\n","        if token.pos_ == \"NOUN\" or token.pos_ == \"PROPN\":\n","            details[\"Skills\"].append(token.text)\n","\n","    return details\n","\n","# Extract the details\n","cv_details = extract_details(doc)\n","\n","# Print the extracted details\n","for key, value in cv_details.items():\n","    print(f\"{key}: {value}\")\n","\n","# Use the given function to extract technical keywords\n","def extract_technical_keywords(text):\n","    doc = nlp(text)\n","    keywords = set()\n","    for ent in doc.ents:\n","        keywords.add(ent.text)\n","    for chunk in doc.noun_chunks:\n","        if \"development\" in chunk.text.lower() or \"integration\" in chunk.text.lower():\n","            keywords.add(chunk.text)\n","    return keywords\n","\n","# Sample skills text for keyword extraction\n","skills_text = \"\"\"\n","Advanced proficiency in JavaScript (ES6+), React, Node.js, and Express for robust full-stack development.\n","Database Management: Skilled in both NoSQL and SQL databases, particularly MongoDB and traditional SQL databases, ensuring data integrity and performance.\n","DevOps & Cloud Services: Experienced with Docker for containerization and AWS for scalable cloud solutions, enhancing deployment processes and application scalability.\n","Version Control: Proficient in using Git for source code management, facilitating team collaboration and code integration.\n","\"\"\"\n","\n","# Extract technical keywords\n","technical_keywords = extract_technical_keywords(skills_text)\n","\n","# Print extracted technical keywords\n","print(\"Extracted Technical Keywords:\")\n","for keyword in sorted(technical_keywords):\n","    print(f\"- {keyword}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"utEBktGWEW5_","executionInfo":{"status":"ok","timestamp":1714891142469,"user_tz":-330,"elapsed":9176,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"6166085b-93a6-46ee-93b2-7af0a2a7f6be"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Name: Gradle\n","Gender: \n","Nationality: \n","Email: \n","Phone: \n","Skills: ['Skills', 'Advanced', 'Android', 'Development', 'Expert', 'Kotlin', 'Java', 'knowledge', 'Android', 'SDK', 'Android', 'Studio', 'Gradle', 'patterns', 'MVVM', 'MVP', 'app', 'development', 'UI', 'UX', 'Design', 'user', 'interfaces', 'Material', 'Design', 'guidelines', 'tools', 'Adobe', 'XD', 'Sketch', 'Backend', 'Integration', 'Android', 'apps', 'APIs', 'GraphQL', 'Firebase', 'services', 'authentication', 'time', 'database', 'cloud', 'messaging', 'Agile', 'Methodology', 'development', 'techniques', 'Scrum', 'Kanban', 'frameworks', 'team', 'productivity', 'project', 'management', 'Continuous', 'Integration', 'Deployment', 'CI', 'CD', 'pipelines', 'Jenkins', 'CircleCI', 'GitHub', 'Actions', 'testing', 'deployment', 'processes', 'Leadership', 'Mentorship', 'leadership', 'Android', 'development', 'teams', 'developers', 'work', 'environment']\n","Total Years of Experience: \n","College Names: ['King Fahd University of Petroleum & Minerals']\n","Degrees: ['\\nPersonal Information\\nName: Nora Al-Faisal\\nGender: Female\\nNationality: Saudi\\nContact Information:\\nEmail: nora.alfaisal@example.com\\nPhone: +966 550 123 456\\nLinkedIn: linkedin.com/in/noraalfaisal-android\\nGitHub: github.com/noraalfaisal\\nEducation\\nBachelor of Science in Computer Engineering, King Fahd University of Petroleum & Minerals, Dhahran, Saudi Arabia, 2009\\nSkills\\nAdvanced Android Development: Expert in Kotlin and Java, with comprehensive knowledge of Android SDK, Android Studio, and Gradle.']\n","Designations: ['Lead Android Developer', 'Android Developer, Tamkeen Technologies']\n","Last Company Names: ['Lead Android Developer', 'Android Developer']\n","Extracted Technical Keywords:\n","- AWS\n","- Database Management\n","- DevOps & Cloud Services\n","- Express\n","- Git\n","- JavaScript\n","- NoSQL\n","- Node.js\n","- React\n","- SQL\n","- Version Control: Proficient\n","- robust full-stack development\n","- team collaboration and code integration\n"]}]},{"cell_type":"markdown","source":["#For skills"],"metadata":{"id":"zHYW8UWr2BAl"}},{"cell_type":"code","source":["import spacy\n","\n","# Load the pre-trained NLP model\n","nlp = spacy.load(\"en_core_web_sm\")\n","\n","# Sample text from the skills description\n","text = \"\"\"\n","Technical Talent Acquisition Mastery: As a Technical Talent Acquisition specialist, your proficiency lies in sourcing, evaluating, and recruiting top technical talent across various roles in the tech industry, such as software engineers, systems analysts, and IT project managers. You possess a deep understanding of the technical skills, qualifications, and experience required for these roles, enabling you to identify and attract the best candidates who can drive innovation and success within the organization.\n","Strategic Recruitment Planning for Tech Industry Success: Your expertise extends to strategic recruitment planning, where you develop and execute recruitment strategies tailored to the specific needs and dynamics of the tech industry. You align these strategies with organizational goals and industry trends, ensuring that your recruitment efforts contribute directly to the organization's success in the highly competitive tech landscape.\n","Advanced Candidate Sourcing Techniques in the Tech Sector: You are an expert in employing a diverse range of sourcing techniques specifically tailored to the tech industry. From leveraging social media platforms and professional networking sites to engaging with tech forums and communities, you adeptly build a robust and diverse candidate pipeline to meet the specialized hiring needs of technical roles.\n","Interviewing & Assessment Proficiency for Technical Roles: Your experience encompasses conducting technical interviews and assessments designed to evaluate candidates' technical proficiency, problem-solving abilities, and cultural fit within the organization. You utilize a combination of technical assessments, coding challenges, and behavioral interviews to thoroughly evaluate candidates and ensure they possess the skills and qualities required for success in technical roles.\n","Market Intelligence & Trend Awareness in Technology Recruitment: You stay abreast of the latest trends, developments, and innovations in both technology and recruitment practices. Your knowledge of emerging technologies, industry trends, and market dynamics enables you to adapt your recruitment strategies proactively, ensuring that your approach remains relevant, competitive, and forward-thinking in the rapidly evolving tech landscape.\n","Effective Stakeholder Collaboration for Tech Talent Acquisition: Collaboration is key in your role as a Technical Talent Acquisition specialist, and you excel in partnering with hiring managers and department heads within the organization. By actively engaging with stakeholders, you gain valuable insights into their hiring needs and priorities, allowing you to provide strategic consultancy and guidance on candidate selection, ultimately facilitating the acquisition of top technical talent to drive organizational success.\n","\n","\"\"\"\n","\n","# Process the text with spaCy\n","doc = nlp(text)\n","\n","# Function to extract keywords based on noun chunks and named entities\n","def extract_technical_keywords(doc):\n","    keywords = set()  # Use a set to avoid duplicates\n","\n","    # Add specific technical terms based on entities and noun chunks\n","    for ent in doc.ents:\n","        if ent.label_ in [\"ORG\", \"PRODUCT\", \"GPE\"]:  # Focus on organizations, products, or technologies\n","            keywords.add(ent.text)\n","\n","    for chunk in doc.noun_chunks:\n","        # Focus on chunks that likely represent technical concepts or tools\n","        if \"model\" in chunk.text.lower() or \"network\" in chunk.text.lower() or \"data\" in chunk.text.lower():\n","            keywords.add(chunk.text)\n","\n","    return keywords\n","\n","# Extract keywords\n","technical_keywords = extract_technical_keywords(doc)\n","\n","# Print the extracted keywords\n","print(\"Extracted Technical Keywords:\")\n","for keyword in sorted(technical_keywords):\n","    print(f\"- {keyword}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jNQFrv3Xegv_","executionInfo":{"status":"ok","timestamp":1715099690484,"user_tz":-330,"elapsed":1653,"user":{"displayName":"Abir Khan","userId":"03467584543916927624"}},"outputId":"7ab73af9-20e3-4734-cd6b-7f83dcb72aa9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Extracted Technical Keywords:\n","- Advanced Candidate Sourcing Techniques\n","- Effective Stakeholder Collaboration for Tech Talent Acquisition:\n","- Interviewing & Assessment Proficiency for Technical Roles\n","- Market Intelligence & Trend Awareness in Technology Recruitment\n","- Strategic Recruitment Planning for Tech Industry Success\n","- Technical Talent Acquisition\n","- Technical Talent Acquisition Mastery\n","- professional networking sites\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"zytzcUAz5oK0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"oe1GYz-J5oQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"7mOlLSuL5oTt"},"execution_count":null,"outputs":[]}]}